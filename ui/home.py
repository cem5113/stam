# ui/home.py
from __future__ import annotations
import os
import streamlit as st

from config.settings import APP_NAME, MODEL_VERSION
from services.tz import now_sf_str
from dataio.loaders import load_sf_crime_latest, load_metadata
from services.metrics import compute_kpis


def _pick_meta(meta: dict) -> tuple[str, str, str]:
    """
    Meta ÅŸemasÄ± esnek olabilir:
    - model.version / model.last_trained_at / data.last_data_refresh_at
    - veya dÃ¼z alanlar: model_version / last_trained_at / last_data_refresh_at|data_refresh_at
    """
    mv = (
        meta.get("model", {}).get("version")
        or meta.get("model_version")
        or MODEL_VERSION
    )
    ltr = (
        meta.get("model", {}).get("last_trained_at")
        or meta.get("last_trained_at")
        or "â€”"
    )
    ldr = (
        meta.get("data", {}).get("last_data_refresh_at")
        or meta.get("last_data_refresh_at")
        or meta.get("data_refresh_at")
        or "â€”"
    )
    return str(mv), str(ltr), str(ldr)


def _get_secret_or_env(key: str, default: str | None = None) -> str | None:
    """Streamlit secrets > ENV fallback."""
    try:
        if key in st.secrets:
            v = st.secrets.get(key, default)  # type: ignore[attr-defined]
            return str(v) if v is not None else default
    except Exception:
        pass
    v = os.getenv(key, default)
    return str(v) if v is not None else None

def _trigger_pipeline() -> tuple[int, str]:
    import os
    repo = os.getenv("GITHUB_REPO")
    wf   = os.getenv("GITHUB_WORKFLOW", "full_pipeline.yml")
    tok  = os.getenv("GH_TOKEN")
    ref  = os.getenv("GITHUB_REF_TO_DISPATCH", "main")  # default branch'iniz master ise burayÄ± 'master' yapÄ±n

    if not (repo and wf and tok):
        return 400, "GITHUB_REPO / GITHUB_WORKFLOW / GH_TOKEN ayarlÄ± deÄŸil."

    try:
        import requests
    except Exception:
        return 400, "requests modÃ¼lÃ¼ yok. requirements.txt iÃ§ine 'requests' ekleyin."

    url = f"https://api.github.com/repos/{repo}/actions/workflows/{wf}/dispatches"
    try:
        r = requests.post(
            url,
            json={"ref": ref},             # ğŸ‘ˆ inputs YOK
            headers={
                "Authorization": f"Bearer {tok}",
                "Accept": "application/vnd.github+json",
            },
            timeout=30,
        )
        return r.status_code, (r.text or "OK")
    except Exception as e:
        return 500, f"Ä°stek hatasÄ±: {e}"

def render():
    st.title(APP_NAME)

    # --- Meta ---
    try:
        meta = load_metadata() or {}
    except Exception:
        meta = {}
    mv, ltr, ldr = _pick_meta(meta)

    # Ãœst bilgi ÅŸeridi
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Model", mv or "â€”")
    c2.metric("Son eÄŸitim (SF)", ltr or "â€”")
    c3.metric("Veri gÃ¼ncelleme (SF)", ldr or "â€”")
    c4.metric("Åu an (SF)", now_sf_str())

    with st.expander("â“˜ Model/Veri Meta", expanded=False):
        st.json(meta, expanded=False)

    # --- GÃ¼ncelleme / Senkronizasyon ---
    st.markdown("#### ğŸ”„ GÃ¼ncelleme / Senkronizasyon")
    colA, colB = st.columns(2)

    if colA.button("âŸ³ Veriyi yeniden yÃ¼kle", use_container_width=True):
        # Streamlit cache temizle â†’ bir sonraki okuma taze veri
        try:
            st.cache_data.clear()  # type: ignore[attr-defined]
        except Exception:
            pass
        # Ä°steÄŸe baÄŸlÄ±: hemen okuma yapÄ±p kullanÄ±cÄ±ya bildirelim
        try:
            _df_chk, _ = load_sf_crime_latest()
            st.success("Veri ve Ã¶zetler yeniden yÃ¼klendi.")
        except Exception as e:
            st.warning("Yeniden yÃ¼kleme Ã§aÄŸrÄ±sÄ± atÄ±ldÄ±; sekmelerde veri okunacaktÄ±r.")
            st.exception(e)

    if colB.button("â–¶ï¸ Full Data Pipelineâ€™Ä± Ã§alÄ±ÅŸtÄ±r", use_container_width=True):
        code, msg = _trigger_pipeline()
        if 200 <= code < 300:
            st.success("âœ… Workflow tetiklendi. GitHub Actions Ã¼zerinden ilerlemeyi izleyebilirsiniz.")
        else:
            st.error(f"âŒ Tetikleme baÅŸarÄ±sÄ±z: {code}\n{msg}")

    st.caption(
        "Not: â€˜Veriyi yeniden yÃ¼kleâ€™ cacheâ€™i boÅŸaltÄ±r ve mevcut artefact/kaynaklarÄ± tekrar okutur. "
        "â€˜Pipelineâ€™ ise ham veriyi toplayÄ±p Ã¶zellik/tahmin/rapor artefactâ€™larÄ±nÄ± yeniden Ã¼retir (opsiyonel)."
    )
    st.markdown("---")

    # --- Veri yÃ¼kleme + KPI ---
    try:
        df, src = load_sf_crime_latest()
    except Exception as e:
        st.error("Veri yÃ¼klenemedi")
        st.exception(e)
        st.stop()
        return

    kpi = compute_kpis(df)
    s1, s2, s3 = st.columns(3)
    s1.metric("HitRate@Top10", "â€”" if kpi["hitrate_top10"] is None else f"{kpi['hitrate_top10']}%")
    s2.metric("Brier", "â€”" if kpi["brier"] is None else f"{kpi['brier']}")

    # Kaynak etiketi
    src_label = {"artifact": "Artifact (gÃ¼ncel)", "release": "Release (yedek)"}.get(str(src), str(src))
    s3.metric("Veri KaynaÄŸÄ±", src_label)

    # Mini Model KartÄ±
    with st.expander("â“˜ Model KartÄ± (mini)", expanded=False):
        st.markdown(
            f"- **SÃ¼rÃ¼m:** {mv}\n"
            f"- **Son eÄŸitim:** {ltr}\n"
            f"- **Veri gÃ¼ncelleme:** {ldr}\n"
            "- **Notlar:** DÃ¼ÅŸÃ¼k olaylÄ± hÃ¼crelerde belirsizlik yÃ¼kselebilir. "
            "Saha gÃ¶rÃ¼nÃ¼mÃ¼nde tahmin seviyesi (YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k) sadeleÅŸtirilmiÅŸtir."
        )

    # KÃ¼Ã§Ã¼k Ã¶nizleme
    with st.expander("Ä°lk 15 satÄ±r (Ã¶nizleme)", expanded=False):
        st.dataframe(df.head(15), use_container_width=True)

    # HÄ±zlÄ± kontroller (yer tutucu)
    st.markdown("#### HÄ±zlÄ± kontroller")
    col1, col2, col3 = st.columns(3)
    col1.toggle("Tahmin katmanÄ± (risk)", value=True, help="AÃ§Ä±lÄ±ÅŸta risk haritasÄ± gÃ¶rÃ¼nÃ¼r.")
    col2.toggle("GeÃ§ici hotspot", value=True, help="Son olaylara dayalÄ± anomali noktalarÄ±.")
    col3.toggle("KalÄ±cÄ± hotspot", value=True, help="Uzun dÃ¶nem Ä±sÄ± haritasÄ±.")
    st.caption("ğŸ”Œ Katmanlar ileride haritaya baÄŸlanacak. KPI'lar gÃ¼ncel veriden otomatik hesaplanÄ±r.")
